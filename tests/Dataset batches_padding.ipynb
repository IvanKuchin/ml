{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset ted_hrlr_translate/pt_to_en/1.0.0 (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\ikuchin\\tensorflow_datasets\\ted_hrlr_translate\\pt_to_en\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9629e9040a426ab4011fd5a1e21357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1af8ec3a4942d7909fcb397e064596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f3653d34294f309c5d7a5e1e47ff9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to C:\\Users\\ikuchin\\tensorflow_datasets\\ted_hrlr_translate\\pt_to_en\\1.0.0.incompleteECTBBA\\ted_hrlr_translate-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321b4be272b445849dd3bc65a9b12074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=51785.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to C:\\Users\\ikuchin\\tensorflow_datasets\\ted_hrlr_translate\\pt_to_en\\1.0.0.incompleteECTBBA\\ted_hrlr_translate-validation.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b82863dd72e402383bc7c57404ca97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1193.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to C:\\Users\\ikuchin\\tensorflow_datasets\\ted_hrlr_translate\\pt_to_en\\1.0.0.incompleteECTBBA\\ted_hrlr_translate-test.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7757769783b4ed48095a9bad386dadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1803.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset ted_hrlr_translate downloaded and prepared to C:\\Users\\ikuchin\\tensorflow_datasets\\ted_hrlr_translate\\pt_to_en\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>,\n",
       " 'train': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>,\n",
       " 'validation': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'e quando melhoramos a procura , tiramos a \\xc3\\xbanica vantagem da impress\\xc3\\xa3o , que \\xc3\\xa9 a serendipidade .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'and when you improve searchability , you actually take away the one advantage of print , which is serendipity .'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'mas e se estes fatores fossem ativos ?'>, <tf.Tensor: shape=(), dtype=string, numpy=b'but what if it were active ?'>)\n"
     ]
    }
   ],
   "source": [
    "def print_first(ds, number_of_items = 2):\n",
    "    for idx, item in zip(range(number_of_items), ds):\n",
    "        print(item)\n",
    "print_first(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus((en.numpy() for pt, en in train_examples), target_vocab_size = 2**13)\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus((pt.numpy() for pt, en in train_examples), target_vocab_size = 2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7915, 1248, 7946, 7194, 13, 2799, 7877]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_en.encode(\"Transformer is awesome.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8087"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_en.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start_stop(lang1, lang2):\n",
    "    start_id_1 = [tokenizer_en.vocab_size]\n",
    "    start_id_2 = [tokenizer_pt.vocab_size]\n",
    "    stop_id_1  = [tokenizer_en.vocab_size + 1]\n",
    "    stop_id_2  = [tokenizer_pt.vocab_size + 1]\n",
    "   \n",
    "#     print(lang1)\n",
    "    lang1 = start_id_1 + tokenizer_pt.encode(lang1.numpy()) +  stop_id_1\n",
    "    lang2 = start_id_2 + tokenizer_en.encode(lang2.numpy()) + stop_id_2\n",
    "\n",
    "    return lang1, lang2\n",
    "\n",
    "def add_start_stop_wrapper(lang1, lang2):\n",
    "    lang1, lang2 = tf.py_function(add_start_stop, [lang1, lang2], [tf.int32, tf.int32])\n",
    "    print(\"1)\", lang2)\n",
    "    lang1.set_shape([None])\n",
    "    lang2.set_shape([None])\n",
    "    print(\"2)\", lang2)\n",
    "    \n",
    "    \n",
    "    return lang1, lang2\n",
    "\n",
    "MAX_SIZE = 40\n",
    "def filter_long_seq(lang1, lang2):\n",
    "    return tf.logical_and(tf.size(lang1) < MAX_SIZE, tf.size(lang2) < MAX_SIZE)\n",
    "# add_start_stop_wrapper('123', '234')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Tensor(\"EagerPyFunc:1\", dtype=int32, device=/job:localhost/replica:0/task:0)\n",
      "2) Tensor(\"EagerPyFunc:1\", shape=(None,), dtype=int32, device=/job:localhost/replica:0/task:0)\n",
      "(<tf.Tensor: shape=(27,), dtype=int32, numpy=\n",
      "array([8087,    6,   40, 4092,   57,    3, 1687,    1, 6155,   12,    3,\n",
      "        461, 6770,   19, 5227, 1088,   97,    1,    5,    8,    3, 4213,\n",
      "       3408, 7256, 1670,    2, 8088])>, <tf.Tensor: shape=(27,), dtype=int32, numpy=\n",
      "array([8214,    4,   59,   15, 1792, 6561, 3060, 7952,    1,   15,  103,\n",
      "        134,  378,    3,   47, 6122,    6, 5311,    1,   91,   13, 1849,\n",
      "        559, 1609,  894,    2, 8215])>)\n",
      "(<tf.Tensor: shape=(11,), dtype=int32, numpy=array([8087,   25,    6,   16,  138, 7800, 2004, 2445, 8073,   29, 8088])>, <tf.Tensor: shape=(9,), dtype=int32, numpy=array([8214,   23,   29,   44,   17,   72, 4332,   33, 8215])>)\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_examples.map(add_start_stop_wrapper)\n",
    "print_first(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Tensor(\"EagerPyFunc:1\", dtype=int32, device=/job:localhost/replica:0/task:0)\n",
      "2) Tensor(\"EagerPyFunc:1\", shape=(None,), dtype=int32, device=/job:localhost/replica:0/task:0)\n",
      "(<tf.Tensor: shape=(1, 27), dtype=int32, numpy=\n",
      "array([[8087,    6,   40, 4092,   57,    3, 1687,    1, 6155,   12,    3,\n",
      "         461, 6770,   19, 5227, 1088,   97,    1,    5,    8,    3, 4213,\n",
      "        3408, 7256, 1670,    2, 8088]])>, <tf.Tensor: shape=(1, 27), dtype=int32, numpy=\n",
      "array([[8214,    4,   59,   15, 1792, 6561, 3060, 7952,    1,   15,  103,\n",
      "         134,  378,    3,   47, 6122,    6, 5311,    1,   91,   13, 1849,\n",
      "         559, 1609,  894,    2, 8215]])>)\n",
      "(<tf.Tensor: shape=(1, 11), dtype=int32, numpy=array([[8087,   25,    6,   16,  138, 7800, 2004, 2445, 8073,   29, 8088]])>, <tf.Tensor: shape=(1, 9), dtype=int32, numpy=array([[8214,   23,   29,   44,   17,   72, 4332,   33, 8215]])>)\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_examples.map(add_start_stop_wrapper).batch(1)\n",
    "print_first(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Tensor(\"EagerPyFunc:1\", dtype=int32, device=/job:localhost/replica:0/task:0)\n",
      "2) Tensor(\"EagerPyFunc:1\", shape=(None,), dtype=int32, device=/job:localhost/replica:0/task:0)\n",
      "(<tf.Tensor: shape=(2, 27), dtype=int32, numpy=\n",
      "array([[8087,    6,   40, 4092,   57,    3, 1687,    1, 6155,   12,    3,\n",
      "         461, 6770,   19, 5227, 1088,   97,    1,    5,    8,    3, 4213,\n",
      "        3408, 7256, 1670,    2, 8088],\n",
      "       [8087,   25,    6,   16,  138, 7800, 2004, 2445, 8073,   29, 8088,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0]])>, <tf.Tensor: shape=(2, 27), dtype=int32, numpy=\n",
      "array([[8214,    4,   59,   15, 1792, 6561, 3060, 7952,    1,   15,  103,\n",
      "         134,  378,    3,   47, 6122,    6, 5311,    1,   91,   13, 1849,\n",
      "         559, 1609,  894,    2, 8215],\n",
      "       [8214,   23,   29,   44,   17,   72, 4332,   33, 8215,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0]])>)\n",
      "(<tf.Tensor: shape=(2, 26), dtype=int32, numpy=\n",
      "array([[8087,   25,   66,   13,  342,    3, 5278, 7990,    4,   38, 3625,\n",
      "        8072,    2, 8088,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0],\n",
      "       [8087,    6,   54, 3906, 2682,  156, 2646, 7990,    8,    3,  496,\n",
      "         139,  216,  354,    1,   21, 1712,  243, 4206,    1,  375,  130,\n",
      "          75, 1960,    2, 8088]])>, <tf.Tensor: shape=(2, 22), dtype=int32, numpy=\n",
      "array([[8214,   23,   25,   98, 7941, 7870,   26,  916,   21, 4287,    2,\n",
      "        8215,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "       [8214,    4,   16, 5443, 3367, 2054,   13,  154, 7936,    1,   37,\n",
      "          45, 2734, 5915, 1510,    1,   31,  211,   24, 3906,    2, 8215]])>)\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_examples.map(add_start_stop_wrapper)\n",
    "train_ds = train_ds.filter(filter_long_seq)\n",
    "train_ds = train_ds.padded_batch(2).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print_first(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22248 time taken: 28.674888134002686\n"
     ]
    }
   ],
   "source": [
    "max_idx = 0\n",
    "start_time = time.time()\n",
    "for idx, item in enumerate(train_ds):\n",
    "    max_idx = idx\n",
    "print(max_idx, \"time taken:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 25892 time taken: 26.984004974365234\n"
     ]
    }
   ],
   "source": [
    "max_idx = 0\n",
    "start_time = time.time()\n",
    "for idx, item in enumerate(train_ds):\n",
    "    max_idx = idx\n",
    "print(\"number of items:\", max_idx, \"time taken:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(2, 27), dtype=int32, numpy=\n",
      "array([[8087,    6,   40, 4092,   57,    3, 1687,    1, 6155,   12,    3,\n",
      "         461, 6770,   19, 5227, 1088,   97,    1,    5,    8,    3, 4213,\n",
      "        3408, 7256, 1670,    2, 8088],\n",
      "       [8087,   25,    6,   16,  138, 7800, 2004, 2445, 8073,   29, 8088,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0]])>, <tf.Tensor: shape=(2, 27), dtype=int32, numpy=\n",
      "array([[8214,    4,   59,   15, 1792, 6561, 3060, 7952,    1,   15,  103,\n",
      "         134,  378,    3,   47, 6122,    6, 5311,    1,   91,   13, 1849,\n",
      "         559, 1609,  894,    2, 8215],\n",
      "       [8214,   23,   29,   44,   17,   72, 4332,   33, 8215,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0]])>)\n",
      "(<tf.Tensor: shape=(2, 26), dtype=int32, numpy=\n",
      "array([[8087,   25,   66,   13,  342,    3, 5278, 7990,    4,   38, 3625,\n",
      "        8072,    2, 8088,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0],\n",
      "       [8087,    6,   54, 3906, 2682,  156, 2646, 7990,    8,    3,  496,\n",
      "         139,  216,  354,    1,   21, 1712,  243, 4206,    1,  375,  130,\n",
      "          75, 1960,    2, 8088]])>, <tf.Tensor: shape=(2, 22), dtype=int32, numpy=\n",
      "array([[8214,   23,   25,   98, 7941, 7870,   26,  916,   21, 4287,    2,\n",
      "        8215,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "       [8214,    4,   16, 5443, 3367, 2054,   13,  154, 7936,    1,   37,\n",
      "          45, 2734, 5915, 1510,    1,   31,  211,   24, 3906,    2, 8215]])>)\n"
     ]
    }
   ],
   "source": [
    "print_first(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
