{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydicom'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-948aa2185bda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_testdata_files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydicom'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "from pydicom.data import get_testdata_files\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import shutil\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"/docs/src/kt/data_by_series_resized\"\n",
    "train_folder = \"/docs/src/kt/data_train\"\n",
    "test_folder = \"/docs/src/kt/data_test\"\n",
    "IMG_PX_SIZE = 150\n",
    "IMG_HEIGHT = 150\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "TRAIN_SET_SIZE = 95\n",
    "EPOCHS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllFoldersList(main_folder):\n",
    "    result = []\n",
    "    for patient_folder in glob.glob(main_folder + \"/*\"):\n",
    "        for series_folder in glob.glob(patient_folder + \"/*\"):\n",
    "            result.append(series_folder)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_to_0_1(arr):\n",
    "    rightMin = 0\n",
    "    rightMax = 1\n",
    "    leftMin = arr.min()\n",
    "    leftMax = arr.max()\n",
    "    # Figure out how 'wide' each range is\n",
    "    leftSpan = leftMax - leftMin\n",
    "    rightSpan = rightMax - rightMin\n",
    "\n",
    "    # Convert the left range into a 0-1 range (float)\n",
    "    valueScaled = (arr - leftMin) / (leftSpan)\n",
    "\n",
    "    # Convert the 0-1 range into a value in the right range.\n",
    "    return rightMin + (valueScaled * rightSpan)\n",
    "\n",
    "def ScaleImageDownTwice(arr):\n",
    "    arr = np.delete(arr, list(range(0, arr.shape[0], 2)), axis=0)\n",
    "    arr = np.delete(arr, list(range(0, arr.shape[1], 2)), axis=1)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def GetPixelDataFromDCIM(image_file):\n",
    "    _dataset = pydicom.dcmread(image_file)\n",
    "    pixel_array = _dataset.pixel_array\n",
    "    del _dataset\n",
    "    return pixel_array\n",
    "\n",
    "def GetScaledPixelDataFromDCIM(image_file):\n",
    "    return scale_to_0_1(GetPixelDataFromDCIM(image_file))\n",
    "\n",
    "\n",
    "# pix_data = ScaleImageDownTwice(GetScaledPixelDataFromDCIM(root_folder + \"/EFREMOV___SERGEY__ALEXEEVICH_VIPROMID370-85ML/5/1.dcm\"))\n",
    "# print(pix_data)\n",
    "# GetScaledPixelDataFromDCIM(root_folder + \"/EFREMOV___SERGEY__ALEXEEVICH_VIPROMID370-85ML/5/2.dcm  \"  )\n",
    "# GetScaledPixelDataFromDCIM(root_folder + \"/EFREMOV___SERGEY__ALEXEEVICH_VIPROMID370-85ML/5/3.dcm  \"  )\n",
    "# GetScaledPixelDataFromDCIM(root_folder + \"/EFREMOV___SERGEY__ALEXEEVICH_VIPROMID370-85ML/5/4.dcm  \"  )\n",
    "# print(pix_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read3DImageFromFolder(folders):\n",
    "    return np.random.randint(10, size=(IMG_HEIGHT, IMG_PX_SIZE, IMG_PX_SIZE, 1))\n",
    "    result = []\n",
    "    for folder in folders:\n",
    "        file_list = []\n",
    "        folder_str = folder.numpy().decode()\n",
    "#         print(\"data:\", folder_str)\n",
    "        for image in glob.glob(folder_str + \"/*.dcm\"):\n",
    "            image_number = int(image[len(folder_str) + 1:-4])\n",
    "            file_list.append(image_number)\n",
    "        file_list = np.sort(np.array(file_list))\n",
    "        single_3d_photo = []\n",
    "        for file_number in file_list:\n",
    "            file_name = folder_str + \"/\" + str(file_number) + \".dcm\"\n",
    "            pixel_data = (GetScaledPixelDataFromDCIM(file_name))\n",
    "            pixel_data = cv2.resize(np.array(pixel_data),(IMG_PX_SIZE,IMG_PX_SIZE))\n",
    "            single_3d_photo.append(pixel_data)\n",
    "        \n",
    "        result = single_3d_photo\n",
    "    result = np.expand_dims(result, axis=3)\n",
    "    return result[:IMG_HEIGHT, ...]\n",
    "\n",
    "# r1 = Read3DImageFromFolder(tf.constant([\"/docs/src/kt/data_by_series_resized\\\\Znamenskaya N.G. - Body 1.0\\\\3\", \"/docs/src/kt/data_by_series_resized\\\\Znamenskaya N.G. - Body 1.0\\\\12\"]))\n",
    "# r1 = Read3DImageFromFolder(tf.constant([\"/docs/src/kt/data_by_series_resized\\\\Znamenskaya N.G. - Body 1.0\\\\3\"]))\n",
    "# t1 = tf.constant(r1)\n",
    "# t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadCategoryFromFolder(folders):\n",
    "    result = []\n",
    "    for folder in folders:\n",
    "        file_list = []\n",
    "        folder_str = folder.numpy().decode()\n",
    "#         print(\"result:\", folder_str, end=\"\")\n",
    "        single_category = []\n",
    "        file_name = folder_str + \"/result\"\n",
    "        try:\n",
    "            f = open(file_name, \"r\")\n",
    "            result = int(f.read())\n",
    "            f.close()\n",
    "#             print(\" -\", result, end=\"\")\n",
    "        except IOError:\n",
    "            print()\n",
    "            print (\"ERROR: Could not read result_file:\", file_name)\n",
    "#         print()\n",
    "    return result\n",
    "\n",
    "# r1 = ReadCategoryFromFolder(tf.constant([\"/docs/src/kt/data_by_series_resized\\\\Buslaev S.N. - Body 1.0\\\\12\"]))\n",
    "# r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def gen(main_folder):\n",
    "    folders_list = GetAllFoldersList(main_folder.decode())\n",
    "    \n",
    "    folders_dataset = tf.data.Dataset.from_tensor_slices(folders_list).shuffle(buffer_size=100).repeat(EPOCHS).batch(1) # --- batch(1) uses to iterate over Dataset, DO NOT mkae it larger than 1\n",
    "\n",
    "    for folders in folders_dataset:\n",
    "        images = Read3DImageFromFolder(folders)\n",
    "        category = ReadCategoryFromFolder(folders)\n",
    "        yield(images, 1)\n",
    "        # yield(images, folders)\n",
    "\n",
    "ds_3d_images = tf.data.Dataset.from_generator(gen, (tf.float32, tf.float32), (tf.TensorShape([IMG_HEIGHT, IMG_PX_SIZE, IMG_PX_SIZE, 1]), tf.TensorShape(())), args=([train_folder])).batch(BATCH_SIZE)\n",
    "\n",
    "# for i, (images, categories) in enumerate(ds_3d_images.take(300)):\n",
    "#     print(\"epoch 1) \" + str(i) + \")\", images.shape, categories.shape)\n",
    "# for i, (images, categories) in enumerate(ds_3d_images.take(300)):\n",
    "#     print(\"epoch 2) \" + str(i) + \")\", images.shape, categories.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 150, 150, 150, 1) 0         \n",
      "_________________________________________________________________\n",
      "conv3d_61 (Conv3D)           (None, 150, 150, 150, 16) 448       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_37 (MaxPooling (None, 75, 75, 75, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 75, 75, 75, 16)    64        \n",
      "_________________________________________________________________\n",
      "conv3d_62 (Conv3D)           (None, 75, 75, 75, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_63 (Conv3D)           (None, 75, 75, 75, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_38 (MaxPooling (None, 18, 18, 18, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 18, 18, 18, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv3d_64 (Conv3D)           (None, 18, 18, 18, 64)    55360     \n",
      "_________________________________________________________________\n",
      "conv3d_65 (Conv3D)           (None, 18, 18, 18, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_39 (MaxPooling (None, 9, 9, 9, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 9, 9, 9, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv3d_66 (Conv3D)           (None, 9, 9, 9, 128)      221312    \n",
      "_________________________________________________________________\n",
      "conv3d_67 (Conv3D)           (None, 9, 9, 9, 128)      442496    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_40 (MaxPooling (None, 4, 4, 4, 128)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 4, 4, 4, 128)      512       \n",
      "_________________________________________________________________\n",
      "conv3d_68 (Conv3D)           (None, 4, 4, 4, 256)      884992    \n",
      "_________________________________________________________________\n",
      "conv3d_69 (Conv3D)           (None, 4, 4, 4, 256)      1769728   \n",
      "_________________________________________________________________\n",
      "max_pooling3d_41 (MaxPooling (None, 2, 2, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 2, 2, 2, 256)      1024      \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 4,643,522\n",
      "Trainable params: 4,642,530\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.layers.Input((IMG_HEIGHT, IMG_PX_SIZE, IMG_PX_SIZE, 1))\n",
    "# input_layer = tf.keras.layers.MaxPool3D(pool_size=(1,2,2))(input_layer)\n",
    "\n",
    "conv_layer_1_1 = tf.keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding='SAME', activation='relu')(input_layer)\n",
    "pooling_layer_1 = tf.keras.layers.MaxPool3D(pool_size=(2,2,2))(conv_layer_1_1)\n",
    "pooling_layer_1 = tf.keras.layers.BatchNormalization()(pooling_layer_1)\n",
    "\n",
    "conv_layer_2_1 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='SAME', activation='relu')(pooling_layer_1)\n",
    "conv_layer_2_2 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='SAME', activation='relu')(conv_layer_2_1)\n",
    "pooling_layer_2 = tf.keras.layers.MaxPool3D(pool_size=(4,4,4))(conv_layer_2_2)\n",
    "pooling_layer_2 = tf.keras.layers.BatchNormalization()(pooling_layer_2)\n",
    "\n",
    "conv_layer_3_1 = tf.keras.layers.Conv3D(filters=64, kernel_size=(3, 3, 3), padding='SAME', activation='relu')(pooling_layer_2)\n",
    "conv_layer_3_2 = tf.keras.layers.Conv3D(filters=64, kernel_size=(3, 3, 3), padding='SAME', activation='relu')(conv_layer_3_1)\n",
    "pooling_layer_3 = tf.keras.layers.MaxPool3D(pool_size=(2,2,2))(conv_layer_3_2)\n",
    "pooling_layer_3 = tf.keras.layers.BatchNormalization()(pooling_layer_3)\n",
    "\n",
    "conv_layer_4_1 = tf.keras.layers.Conv3D(filters=128, kernel_size=(3, 3, 3), padding='SAME', activation='relu')(pooling_layer_3)\n",
    "conv_layer_4_2 = tf.keras.layers.Conv3D(filters=128, kernel_size=(3, 3, 3), padding='SAME', activation='relu')(conv_layer_4_1)\n",
    "pooling_layer_4 = tf.keras.layers.MaxPool3D(pool_size=(2,2,2))(conv_layer_4_2)\n",
    "pooling_layer_4 = tf.keras.layers.BatchNormalization()(pooling_layer_4)\n",
    "\n",
    "conv_layer_5_1 = tf.keras.layers.Conv3D(filters=256, kernel_size=(3, 3, 3), padding='SAME', activation='relu')(pooling_layer_4)\n",
    "conv_layer_5_2 = tf.keras.layers.Conv3D(filters=256, kernel_size=(3, 3, 3), padding='SAME', activation='relu')(conv_layer_5_1)\n",
    "pooling_layer_5 = tf.keras.layers.MaxPool3D(pool_size=(2,2,2))(conv_layer_5_2)\n",
    "pooling_layer_5 = tf.keras.layers.BatchNormalization()(pooling_layer_5)\n",
    "\n",
    "# conv_layer_6_1 = tf.keras.layers.Conv3D(filters=4, kernel_size=(3, 3, 3), padding='SAME', activation='relu')(pooling_layer_5)\n",
    "# conv_layer_6_2 = tf.keras.layers.Conv3D(filters=4, kernel_size=(3, 3, 3), padding='SAME', activation='relu')(conv_layer_6_1)\n",
    "# pooling_layer_6 = tf.keras.layers.MaxPool3D(pool_size=(2,2,2))(conv_layer_6_2)\n",
    "# pooling_layer_6 = tf.keras.layers.BatchNormalization()(pooling_layer_6)\n",
    "\n",
    "# conv_layer_7_1 = tf.keras.layers.Conv3D(filters=4, kernel_size=(3, 3, 3), padding='SAME', activation='relu')(pooling_layer_6)\n",
    "# conv_layer_7_2 = tf.keras.layers.Conv3D(filters=4, kernel_size=(3, 3, 3), padding='SAME', activation='relu')(conv_layer_7_1)\n",
    "# pooling_layer_7 = tf.keras.layers.MaxPool3D(pool_size=(2,2,2))(conv_layer_7_2)\n",
    "# pooling_layer_7 = tf.keras.layers.BatchNormalization()(pooling_layer_7)\n",
    "\n",
    "# conv_layer_8_1 = tf.keras.layers.Conv3D(filters=4, kernel_size=(3, 3, 3), padding='SAME', activation='relu')(pooling_layer_7)\n",
    "# conv_layer_8_2 = tf.keras.layers.Conv3D(filters=4, kernel_size=(3, 3, 3), padding='SAME', activation='relu')(conv_layer_8_1)\n",
    "# pooling_layer_8 = tf.keras.layers.MaxPool3D(pool_size=(1,2,2))(conv_layer_8_2)\n",
    "# pooling_layer_8 = tf.keras.layers.BatchNormalization()(pooling_layer_8)\n",
    "\n",
    "flatten_layer = tf.keras.layers.Flatten()(pooling_layer_5)\n",
    "dense_layer_1 = tf.keras.layers.Dense(units=512, activation='relu')(flatten_layer)\n",
    "dense_layer_1 = tf.keras.layers.Dropout(0.4)(dense_layer_1)\n",
    "\n",
    "dense_layer_2 = tf.keras.layers.Dense(units=128, activation='relu')(dense_layer_1)\n",
    "dense_layer_2 = tf.keras.layers.Dropout(0.4)(dense_layer_2)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(units=2, activation=\"softmax\")(dense_layer_2)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 14 steps\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 929s 66s/step - loss: 3.0442 - acc: 0.4571\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 938s 67s/step - loss: 6.9036 - acc: 0.5286\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 937s 67s/step - loss: 17.2546 - acc: 0.5571\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 927s 66s/step - loss: 46.2137 - acc: 0.4857\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 962s 69s/step - loss: 132.8734 - acc: 0.4571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27346f46c88>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy, \n",
    "    optimizer=tf.keras.optimizers.Adadelta(lr=0.1),\n",
    "#     optimizer=tf.keras.optimizers.SGD(lr=0.1),\n",
    "    metrics=['acc'],\n",
    ")\n",
    "model.fit(\n",
    "    ds_3d_images, \n",
    "#     batch_size = BATCH_SIZE,\n",
    "    steps_per_epoch = int(0.75 * TRAIN_SET_SIZE / BATCH_SIZE),\n",
    "    epochs=EPOCHS,\n",
    "#     validation_steps= int(0.25 * TRAIN_SET_SIZE / BATCH_SIZE),\n",
    "#     validation_split = 0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4, 4)\n",
      "min/mean/max: 0.027040005 / 0.52522343 / 0.984082\n",
      "shape: (2, 8, 2)\n",
      "min/mean/max: 0.027039228 / 0.4877246 / 0.9616642\n"
     ]
    }
   ],
   "source": [
    "import scipy \n",
    "\n",
    "def print_mmm(image):\n",
    "    print(\"shape:\", image.shape)\n",
    "    print(\"min/mean/max:\", tf.reduce_min(image).numpy(), \"/\", tf.reduce_mean(image).numpy(), \"/\", tf.reduce_max(image).numpy())\n",
    "\n",
    "image = tf.random.uniform([4,4,4])\n",
    "\n",
    "resized = scipy.ndimage.interpolation.zoom(image, [0.5, 2, 0.5], mode='nearest')\n",
    "resized = tf.constant(resized)\n",
    "\n",
    "print_mmm(image)\n",
    "print_mmm(resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4, 4), dtype=float32, numpy=\n",
       "array([[[0.84187806, 0.5573448 , 0.34999144, 0.06506217],\n",
       "        [0.55381167, 0.0343641 , 0.65506196, 0.6715872 ],\n",
       "        [0.31421995, 0.48615813, 0.65227973, 0.46496677],\n",
       "        [0.25730324, 0.79663146, 0.01746976, 0.14161444]],\n",
       "\n",
       "       [[0.02585554, 0.7919868 , 0.9287137 , 0.38074052],\n",
       "        [0.31787026, 0.19719243, 0.79352427, 0.27093828],\n",
       "        [0.6273056 , 0.72384155, 0.5933081 , 0.40816545],\n",
       "        [0.42199743, 0.13566446, 0.53628683, 0.5728426 ]],\n",
       "\n",
       "       [[0.68400955, 0.5745909 , 0.8713881 , 0.9711107 ],\n",
       "        [0.18697202, 0.35425985, 0.99993443, 0.12721133],\n",
       "        [0.9574194 , 0.61155534, 0.6691923 , 0.2826203 ],\n",
       "        [0.12715137, 0.8551297 , 0.782622  , 0.5331627 ]],\n",
       "\n",
       "       [[0.3199923 , 0.17942894, 0.83908844, 0.01429558],\n",
       "        [0.43708205, 0.1459732 , 0.15967226, 0.9531288 ],\n",
       "        [0.1951623 , 0.2124896 , 0.7779074 , 0.45443773],\n",
       "        [0.8146492 , 0.48838186, 0.29972136, 0.8965018 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
